参考文档：
https://langchain-ai.github.io/langgraph/agents/models/


本页介绍如何配置代理使用的聊天模型。

工具调用支持¶
要启用工具调用代理，底层 LLM 必须支持工具调用。

兼容的模型可以在 LangChain 集成目录中找到。



```python
import os
from langchain.chat_models import init_chat_model
from langgraph.prebuilt import create_react_agent

API_KEY = "sk-123"

BASE_URL = "https://api.deepseek.com"

os.environ["OPENAI_API_KEY"] = API_KEY
os.environ["OPENAI_API_BASE"] = BASE_URL


llm = init_chat_model(model="openai:deepseek-chat",
                      disable_streaming=True,# 禁用流式传输
                      temperature=0.1,
                      max_tokens=10240
                      )

agent = create_react_agent(
    model=llm,
tools=[],
)

```
