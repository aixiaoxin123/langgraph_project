{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6081d627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"what's 3 + 5 and 4 * 7?\", additional_kwargs={}, response_metadata={}, id='fceea18f-cb68-461a-a690-1dbcc6d52567'),\n",
       "  AIMessage(content='3 + 5 equals **8**.\\n\\nFor 4 * 7, let me calculate that for you.', additional_kwargs={'tool_calls': [{'id': 'call_0_e9c90af1-c68c-41dc-be12-4612284ebe54', 'function': {'arguments': '{\"a\":4,\"b\":7}', 'name': 'multiply_tool'}, 'type': 'function', 'index': 0}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 46, 'prompt_tokens': 149, 'total_tokens': 195, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 149}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_8802369eaa_prod0425fp8', 'id': '87e4552d-220f-4338-ac35-ac635321d25d', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--93c67b97-d22e-407e-ad0b-02074b3953b8-0', tool_calls=[{'name': 'multiply_tool', 'args': {'a': 4, 'b': 7}, 'id': 'call_0_e9c90af1-c68c-41dc-be12-4612284ebe54', 'type': 'tool_call'}], usage_metadata={'input_tokens': 149, 'output_tokens': 46, 'total_tokens': 195, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}),\n",
       "  ToolMessage(content='28', name='multiply_tool', id='bdcfafb4-56fe-4ea7-89a4-8766ef707872', tool_call_id='call_0_e9c90af1-c68c-41dc-be12-4612284ebe54'),\n",
       "  AIMessage(content='4 * 7 equals **28**. \\n\\nSo, the answers are:\\n- 3 + 5 = **8**\\n- 4 * 7 = **28**', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 35, 'prompt_tokens': 204, 'total_tokens': 239, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 128}, 'prompt_cache_hit_tokens': 128, 'prompt_cache_miss_tokens': 76}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_8802369eaa_prod0425fp8', 'id': '34be8093-45e0-4b2e-a6da-911eaa09d8f5', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--145ee016-f074-476c-b38f-5d8183d323f5-0', usage_metadata={'input_tokens': 204, 'output_tokens': 35, 'total_tokens': 239, 'input_token_details': {'cache_read': 128}, 'output_token_details': {}})]}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "API_KEY = \"sk-123\"\n",
    "\n",
    "BASE_URL = \"https://api.deepseek.com\"\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = API_KEY\n",
    "os.environ[\"OPENAI_API_BASE\"] = BASE_URL\n",
    "\n",
    "\n",
    "llm = init_chat_model(model=\"openai:deepseek-chat\",\n",
    "                      disable_streaming=True,# 禁用流式传输\n",
    "                      temperature=0.1,\n",
    "                      max_tokens=10240\n",
    "                      )\n",
    "\n",
    "\n",
    "# 定义工具\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool(\"multiply_tool\", parse_docstring=True)\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\n",
    "\n",
    "    Args:\n",
    "        a: First operand\n",
    "        b: Second operand\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "\n",
    "#您还可以使用 Pydantic 定义自定义输入架构：\n",
    "\n",
    "\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class MultiplyInputSchema(BaseModel):\n",
    "    \"\"\"Multiply two numbers\"\"\"\n",
    "    a: int = Field(description=\"First operand\")\n",
    "    b: int = Field(description=\"Second operand\")\n",
    "\n",
    "@tool(\"multiply_tool\", args_schema=MultiplyInputSchema)\n",
    "def multiply_pydantic(a: int, b: int) -> int:\n",
    "    return a * b\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model=llm,\n",
    "tools=[multiply],\n",
    ")\n",
    "\n",
    "agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what's 3 + 5 and 4 * 7?\"}]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d0a7a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"what's 3 + 5?\", additional_kwargs={}, response_metadata={}, id='c9095131-05b8-4423-8c99-fa5a29f583d7'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_0_e3d3f882-752a-4df9-bba6-79cdc2047151', 'function': {'arguments': '{\"a\":3,\"b\":5}', 'name': 'add'}, 'type': 'function', 'index': 0}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 121, 'total_tokens': 143, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 121}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_8802369eaa_prod0425fp8', 'id': '785c221b-bd94-48f8-9b68-7ef7838eb5ac', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--06a2b4b5-8aea-485f-9b62-515958aac8d5-0', tool_calls=[{'name': 'add', 'args': {'a': 3, 'b': 5}, 'id': 'call_0_e3d3f882-752a-4df9-bba6-79cdc2047151', 'type': 'tool_call'}], usage_metadata={'input_tokens': 121, 'output_tokens': 22, 'total_tokens': 143, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}),\n",
       "  ToolMessage(content='8', name='add', id='a4ddc71d-0243-4aff-abb1-68df21bb3563', tool_call_id='call_0_e3d3f882-752a-4df9-bba6-79cdc2047151')]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 直接返回工具结果¶\n",
    "# 用于立即返回工具结果并停止代理循环：return_direct=True\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool(return_direct=True)\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two numbers\"\"\"\n",
    "    return a + b\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model=llm,\n",
    "    tools=[add]\n",
    ")\n",
    "\n",
    "agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what's 3 + 5?\"}]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "439b03e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Hi, I am Bob', additional_kwargs={}, response_metadata={}, id='36e5a489-a431-457f-9b6b-f10da043223d'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_0_f3aeca2e-8434-4224-a8c8-1d1a173a9f9d', 'function': {'arguments': '{\"user_name\":\"Bob\"}', 'name': 'greet'}, 'type': 'function', 'index': 0}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 104, 'total_tokens': 124, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 104}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_8802369eaa_prod0425fp8', 'id': '0439d763-8d04-449b-baaf-753ebbbda378', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--7ee1aaa2-ddc7-4aea-81f0-4578c83bf5e6-0', tool_calls=[{'name': 'greet', 'args': {'user_name': 'Bob'}, 'id': 'call_0_f3aeca2e-8434-4224-a8c8-1d1a173a9f9d', 'type': 'tool_call'}], usage_metadata={'input_tokens': 104, 'output_tokens': 20, 'total_tokens': 124, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}),\n",
       "  ToolMessage(content='Hello Bob!', name='greet', id='7a1c9e96-520b-44c5-8334-92e6efd4a34b', tool_call_id='call_0_f3aeca2e-8434-4224-a8c8-1d1a173a9f9d')]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 强制使用工具¶\n",
    "# 要强制代理使用特定工具，您可以在 ：tool_choicemodel.bind_tools()\n",
    "\n",
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "API_KEY = \"sk-123\"\n",
    "\n",
    "BASE_URL = \"https://api.deepseek.com\"\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = API_KEY\n",
    "os.environ[\"OPENAI_API_BASE\"] = BASE_URL\n",
    "\n",
    "\n",
    "llm = init_chat_model(model=\"openai:deepseek-chat\",\n",
    "                      disable_streaming=True,# 禁用流式传输\n",
    "                      temperature=0.1,\n",
    "                      max_tokens=10240\n",
    "                      )\n",
    "\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool(return_direct=True)\n",
    "def greet(user_name: str) -> int:\n",
    "    \"\"\"Greet user.\"\"\"\n",
    "    return f\"Hello {user_name}!\"\n",
    "\n",
    "tools = [greet]\n",
    "\n",
    "llm.bind_tools(tools, tool_choice={\"type\": \"tool\", \"name\": \"greet\"})\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model=llm,\n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Hi, I am Bob\"}]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49c58d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"what's 42 x 7?\", additional_kwargs={}, response_metadata={}, id='2f76cea0-a04a-4f63-9cf0-78e814babfc2'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_0_3e20f59c-8e73-4db7-afb1-0a9bf9abcf07', 'function': {'arguments': '{\"a\":42,\"b\":7}', 'name': 'multiply'}, 'type': 'function', 'index': 0}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 123, 'total_tokens': 146, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 123}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_8802369eaa_prod0425fp8', 'id': '3c6dca32-12a1-4826-b419-2a9a852496db', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--0d66d28c-f0e0-4d92-b5dd-813435065e82-0', tool_calls=[{'name': 'multiply', 'args': {'a': 42, 'b': 7}, 'id': 'call_0_3e20f59c-8e73-4db7-afb1-0a9bf9abcf07', 'type': 'tool_call'}], usage_metadata={'input_tokens': 123, 'output_tokens': 23, 'total_tokens': 146, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}),\n",
       "  ToolMessage(content=\"Error: ValueError('The ultimate error')\\n Please fix your mistakes.\", name='multiply', id='ac156e21-0945-4474-90e0-71d392d0b8e0', tool_call_id='call_0_3e20f59c-8e73-4db7-afb1-0a9bf9abcf07', status='error'),\n",
       "  AIMessage(content='It seems there was an error calculating the product of 42 and 7. Let me try again manually:\\n\\n42 × 7 = 294.\\n\\nThe answer is 294.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 166, 'total_tokens': 202, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 64}, 'prompt_cache_hit_tokens': 64, 'prompt_cache_miss_tokens': 102}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_8802369eaa_prod0425fp8', 'id': '2b35551a-4aab-40f6-8d95-5bb1fc334b3e', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--36d6b13c-680a-4aec-bd83-0eb20f8994bc-0', usage_metadata={'input_tokens': 166, 'output_tokens': 36, 'total_tokens': 202, 'input_token_details': {'cache_read': 64}, 'output_token_details': {}})]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 处理工具错误¶\n",
    "# 默认情况下，代理将捕获工具调用期间引发的所有异常，并将这些异常作为工具消息传递给 LLM。要控制错误的处理方式，您可以通过其参数使用预构建的 ToolNode（在其中执行工具的节点）\n",
    "\n",
    "\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    if a == 42:\n",
    "        raise ValueError(\"The ultimate error\")\n",
    "    return a * b\n",
    "\n",
    "# Run with error handling (default)\n",
    "agent = create_react_agent(\n",
    "    model=\"openai:deepseek-chat\",\n",
    "    tools=[multiply]\n",
    ")\n",
    "agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what's 42 x 7?\"}]}\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
