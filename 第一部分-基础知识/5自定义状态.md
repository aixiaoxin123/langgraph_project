参考文档教程：
https://langchain-ai.github.io/langgraph/tutorials/get-started/5-customize-state/



```python
# https://python.langchain.com/docs/integrations/tools/tavily_search/

# 获取密钥的地址： https://app.tavily.com/sign-in




import os
TAVILY_API_KEY="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"
os.environ["TAVILY_API_KEY"] = TAVILY_API_KEY

```


```python
from langchain_tavily import TavilySearch

tool = TavilySearch(max_results=5)
tools = [tool]
tool.invoke("What's a 'node' in LangGraph?")

```




    {'query': "What's a 'node' in LangGraph?",
     'follow_up_questions': None,
     'answer': None,
     'images': [],
     'results': [{'title': 'What is LangGraph? - IBM',
       'url': 'https://www.ibm.com/think/topics/langgraph',
       'content': 'LangGraph, created by LangChain, is an open source AI agent framework designed to build, deploy and manage complex generative AI agent workflows. At its core, LangGraph uses the power of graph-based architectures to model and manage the intricate relationships between various components of an AI agent workflow. LangGraph illuminates the processes within an AI workflow, allowing full transparency of the agent’s state. By combining these technologies with a set of APIs and tools, LangGraph provides users with a versatile platform for developing AI solutions and workflows including chatbots, state graphs and other agent-based systems. Nodes: In LangGraph, nodes represent individual components or agents within an AI workflow. LangGraph uses enhanced decision-making by modeling complex relationships between nodes, which means it uses AI agents to analyze their past actions and feedback.',
       'score': 0.90907925,
       'raw_content': None},
      {'title': 'Nodes and Edges | langchain-ai/langgraph-101 | DeepWiki',
       'url': 'https://deepwiki.com/langchain-ai/langgraph-101/2.2-nodes-and-edges',
       'content': 'Nodes and Edges | langchain-ai/langgraph-101 | DeepWiki Nodes and Edges Nodes and Edges What are Nodes and Edges? In LangGraph, a graph is composed of nodes connected by edges to form a directed workflow. Nodes are the workhorses of LangGraph - they are Python functions that receive the current graph state as input, perform operations, and return updates to that state. Edges define the flow of execution between nodes in a LangGraph. graph_builder.add_edge("retrieve_documents", "generate_response") Conditional edges use a function to determine the next node based on the current state. Building a Graph with Nodes and Edges graph_builder.add_node("retrieve_documents", retrieve_documents) graph_builder.add_edge("retrieve_documents", "generate_response") When designing nodes and edges in LangGraph: Nodes and Edges What are Nodes and Edges? Building a Graph with Nodes and Edges',
       'score': 0.8559598,
       'raw_content': None},
      {'title': "An Absolute Beginner's Guide to LangGraph.js",
       'url': 'https://techcommunity.microsoft.com/blog/educatordeveloperblog/an-absolute-beginners-guide-to-langgraph-js/4212496',
       'content': "We'll add the name and isHuman properties to our State object and update the sayHello and sayBye nodes to use these State object properties. Update the Graph's nodes and edges: We'll build a graph that returns a random fact or joke based on the user's input. Finally, inside src/index.ts, import and execute the Graph with a user input, inside the /joke-or-fact route: In this guide, we've covered the basics of LangGraph.js, building a simple graph that returns a random fact or joke based on user input. We've learned how to define nodes, edges, and state objects and how to add conditional routing to our Graph. LangGraph.js is a powerful tool for building complex workflows and managing State in your applications.",
       'score': 0.59457535,
       'raw_content': None},
      {'title': 'LangGraph cheatsheet · GitHub',
       'url': 'https://gist.github.com/razhangwei/631a799e6bd69b26ce9c118c624cd80d',
       'content': 'This is an excellent LangGraph cheat sheet! LangGraph Cheat Sheet 3. Create Nodes Example Node Function: 4. Create the Graph 5. Add Nodes to the Graph 9. Compile the Graph Invoke the Graph StateGraph | Main class for creating a graph add_node() | Adds a node to the graph add_edge() | Adds a direct edge between two nodes add_conditional_edges() | Adds conditional edges based on a routing function set_entry_point() | Sets the starting node of the graph compile() | Compiles the graph into a RunnableGraph invoke() | Executes the graph with an initial state Send() | Dispatches tasks to multiple nodes in parallel This cheat sheet provides you with all essential steps, best practices, and examples for building LangGraph workflows efficiently! Footer Footer navigation',
       'score': 0.5654673,
       'raw_content': None},
      {'title': 'How to Build AI Agents with LangGraph: A Step-by-Step Guide',
       'url': 'https://medium.com/@lorevanoudenhove/how-to-build-ai-agents-with-langgraph-a-step-by-step-guide-5d84d9c7e832',
       'content': 'In this step, we’ll define how the AI agent manages its state (the ongoing context of the conversation) and ensure it responds appropriately to the user’s input and tool output. This involves creating a template for the conversation, specifying the tools that the assistant will use, and configuring how the AI agent will respond to user input and trigger different functions (like calculating solar savings). This step ensures that the AI assistant can access and trigger the tools as needed during the conversation, creating a seamless interaction between the user and the assistant. By following these steps, you have successfully created an AI assistant using LangGraph that can calculate solar panel energy savings based on user inputs.',
       'score': 0.092532046,
       'raw_content': None}],
     'response_time': 1.66}




```python
import os
from langchain.chat_models import init_chat_model

API_KEY = "sk-123"

BASE_URL = "https://api.deepseek.com"

os.environ["OPENAI_API_KEY"] = API_KEY
os.environ["OPENAI_API_BASE"] = BASE_URL


llm = init_chat_model("openai:deepseek-chat")
```


```python
from typing import Annotated

from langchain_tavily import TavilySearch
from langchain_core.messages import BaseMessage
from typing_extensions import TypedDict
from langchain_core.tools import tool
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode, tools_condition

from langgraph.types import Command, interrupt


from langchain_core.messages import ToolMessage
from langchain_core.tools import InjectedToolCallId, tool

from langgraph.types import Command, interrupt

class State(TypedDict):
    messages: Annotated[list, add_messages]
    name: str
    birthday: str


graph_builder = StateGraph(State)

@tool
# Note that because we are generating a ToolMessage for a state update, we
# generally require the ID of the corresponding tool call. We can use
# LangChain's InjectedToolCallId to signal that this argument should not
# be revealed to the model in the tool's schema.
def human_assistance(
    name: str, birthday: str, tool_call_id: Annotated[str, InjectedToolCallId]
) -> str:
    """Request assistance from a human."""
    human_response = interrupt(
        {
            "question": "Is this correct?",
            "name": name,
            "birthday": birthday,
        },
    )
    # If the information is correct, update the state as-is.
    if human_response.get("correct", "").lower().startswith("y"):
        verified_name = name
        verified_birthday = birthday
        response = "Correct"
    # Otherwise, receive information from the human reviewer.
    else:
        verified_name = human_response.get("name", name)
        verified_birthday = human_response.get("birthday", birthday)
        response = f"Made a correction: {human_response}"

    # This time we explicitly update the state with a ToolMessage inside
    # the tool.
    state_update = {
        "name": verified_name,
        "birthday": verified_birthday,
        "messages": [ToolMessage(response, tool_call_id=tool_call_id)],
    }
    # We return a Command object in the tool to update our state.
    return Command(update=state_update)



tool = TavilySearch(max_results=2)

tools = [tool,human_assistance] # 添加human_assistance工具

llm_with_tools = llm.bind_tools(tools)

def chatbot(state: State):
    return {"messages": [llm_with_tools.invoke(state["messages"])]}

graph_builder.add_node("chatbot", chatbot)

tool_node = ToolNode(tools=tools)
graph_builder.add_node("tools", tool_node)

graph_builder.add_conditional_edges(
    "chatbot",
    tools_condition,
)
# Any time a tool is called, we return to the chatbot to decide the next step
graph_builder.add_edge("tools", "chatbot")
graph_builder.add_edge(START, "chatbot")
graph = graph_builder.compile()
```


```python
# 添加内存功能
from langgraph.checkpoint.memory import MemorySaver

memory = MemorySaver()
graph = graph_builder.compile(checkpointer=memory)
```


```python
from IPython.display import Image, display

try:
    display(Image(graph.get_graph().draw_mermaid_png()))
except Exception:
    # This requires some extra dependencies and is optional
    pass
```


    
![png](5%E8%87%AA%E5%AE%9A%E4%B9%89%E7%8A%B6%E6%80%81_files/5%E8%87%AA%E5%AE%9A%E4%B9%89%E7%8A%B6%E6%80%81_6_0.png)
    



```python
#与您的聊天机器人互动


config = {"configurable": {"thread_id": "1"}}


user_input = (
    "Can you look up when LangGraph was released? "
    "When you have the answer, use the human_assistance tool for review."
)

# The config is the **second positional argument** to stream() or invoke()!
events = graph.stream(
    {"messages": [{"role": "user", "content": user_input}]},
    config,
    stream_mode="values",
)
for event in events:
    if "messages" in event:
        event["messages"][-1].pretty_print()
    
```

    ================================[1m Human Message [0m=================================
    
    Can you look up when LangGraph was released? When you have the answer, use the human_assistance tool for review.
    ==================================[1m Ai Message [0m==================================
    Tool Calls:
      tavily_search (call_0_4f41d3f3-0512-440f-b690-56b476b58855)
     Call ID: call_0_4f41d3f3-0512-440f-b690-56b476b58855
      Args:
        query: LangGraph release date
    =================================[1m Tool Message [0m=================================
    Name: tavily_search
    
    {"query": "LangGraph release date", "follow_up_questions": null, "answer": null, "images": [], "results": [{"title": "Releases · langchain-ai/langgraph - GitHub", "url": "https://github.com/langchain-ai/langgraph/releases", "content": "Releases · langchain-ai/langgraph GitHub Copilot Write better code with AI GitHub Advanced Security Find and fix vulnerabilities Code Search Find more, search less *   Why GitHub *   GitHub Advanced Security Enterprise-grade security features Search code, repositories, users, issues, pull requests... Releases: langchain-ai/langgraph Releases · langchain-ai/langgraph github-actions github-actions [docs] LangGraph / LangGraph Platform docs updates (#4479) Add clear cache methods github-actions Changes since checkpoint==2.0.25 checkpoint: release 2.0.26 (#4708) docs(reference): filter class methods and add missing docstrings (#4463) github-actions Update python SDK docstrings (#4602) github-actions github-actions feat: CLI: Add main.py (#4637) github-actions github-actions fix for langgraph docstring fixes for libs/langgraph docs: update add_messages API ref (#4495) github-actions Release checkpoint-sqlite (#4509) docstrings for checkpoint-sqlite Add delete_thread method to Checkpointer class (#4328) github-actions", "score": 0.57035583, "raw_content": null}, {"title": "Announcing LangGraph v0.1 & LangGraph Cloud: Running agents at scale ...", "url": "https://blog.langchain.dev/langgraph-cloud/", "content": "Announcing LangGraph v0.1 & LangGraph Cloud: Running agents at scale, reliably Our new infrastructure for running agents at scale, LangGraph Cloud, is available in beta. Separate from the langchain package, LangGraph’s core design philosophy is to help developers add better precision and control into agentic workflows, suitable for the complexity of real-world systems. LangGraph Cloud, currently in closed beta, is infrastructure for deploying your LangGraph agents in a scalable, fault tolerant way. LangGraph Cloud: Scalable agent deployment with integrated monitoring To complement the LangGraph framework, we also have a new runtime, LangGraph Cloud, now available in beta, which provides infrastructure purpose-built for deploying agents at scale. LangGraph Cloud also brings a more integrated experience for collaborating on, deploying, and monitoring your agentic app.", "score": 0.30856565, "raw_content": null}], "response_time": 0.46}
    ==================================[1m Ai Message [0m==================================
    Tool Calls:
      human_assistance (call_0_7a301df6-bb5a-41da-8af3-6e55f3999bed)
     Call ID: call_0_7a301df6-bb5a-41da-8af3-6e55f3999bed
      Args:
        name: LangGraph Release Date Review
        birthday: 2023-01-01
    


```python
snapshot = graph.get_state(config)
snapshot.next
```




    ('tools',)




```python
#  添加人工协助

human_command = Command(
    resume={
        "name": "LangGraph",
        "birthday": "Jan 17, 2024",
    },
)


events = graph.stream(human_command, config, stream_mode="values")
for event in events:
    if "messages" in event:
        event["messages"][-1].pretty_print()
```

    ==================================[1m Ai Message [0m==================================
    Tool Calls:
      human_assistance (call_0_7a301df6-bb5a-41da-8af3-6e55f3999bed)
     Call ID: call_0_7a301df6-bb5a-41da-8af3-6e55f3999bed
      Args:
        name: LangGraph Release Date Review
        birthday: 2023-01-01
    =================================[1m Tool Message [0m=================================
    Name: human_assistance
    
    Made a correction: {'name': 'LangGraph', 'birthday': 'Jan 17, 2024'}
    ==================================[1m Ai Message [0m==================================
    
    It appears that LangGraph was released on **January 17, 2024**. Let me know if you'd like any additional details!
    


```python
# 查看当前状态
snapshot = graph.get_state(config)

{k: v for k, v in snapshot.values.items() if k in ("name", "birthday")}
```




    {'name': 'LangGraph', 'birthday': 'Jan 17, 2024'}




```python
# 自定义修改状态

# 打印状态值
print(snapshot.values.items())


graph.update_state(config, {"name": "LangGraph (library)"})
# 打印值
{k: v for k, v in snapshot.values.items() if k in ("name", "birthday")}
```

    dict_items([('messages', [HumanMessage(content='Can you look up when LangGraph was released? When you have the answer, use the human_assistance tool for review.', additional_kwargs={}, response_metadata={}, id='1f81e5da-c9ed-4b6f-b7a2-ddb15bf48724'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_0_4f41d3f3-0512-440f-b690-56b476b58855', 'function': {'arguments': '{"query":"LangGraph release date"}', 'name': 'tavily_search'}, 'type': 'function', 'index': 0}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 1362, 'total_tokens': 1385, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 1216}, 'prompt_cache_hit_tokens': 1216, 'prompt_cache_miss_tokens': 146}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_8802369eaa_prod0425fp8', 'id': '6b78d8a8-4db3-453f-9375-b38e524194c0', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--fb61661f-0460-47d7-adb9-d4f85d900f26-0', tool_calls=[{'name': 'tavily_search', 'args': {'query': 'LangGraph release date'}, 'id': 'call_0_4f41d3f3-0512-440f-b690-56b476b58855', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1362, 'output_tokens': 23, 'total_tokens': 1385, 'input_token_details': {'cache_read': 1216}, 'output_token_details': {}}), ToolMessage(content='{"query": "LangGraph release date", "follow_up_questions": null, "answer": null, "images": [], "results": [{"title": "Releases · langchain-ai/langgraph - GitHub", "url": "https://github.com/langchain-ai/langgraph/releases", "content": "Releases · langchain-ai/langgraph GitHub Copilot Write better code with AI GitHub Advanced Security Find and fix vulnerabilities Code Search Find more, search less *   Why GitHub *   GitHub Advanced Security Enterprise-grade security features Search code, repositories, users, issues, pull requests... Releases: langchain-ai/langgraph Releases · langchain-ai/langgraph github-actions github-actions [docs] LangGraph / LangGraph Platform docs updates (#4479) Add clear cache methods github-actions Changes since checkpoint==2.0.25 checkpoint: release 2.0.26 (#4708) docs(reference): filter class methods and add missing docstrings (#4463) github-actions Update python SDK docstrings (#4602) github-actions github-actions feat: CLI: Add main.py (#4637) github-actions github-actions fix for langgraph docstring fixes for libs/langgraph docs: update add_messages API ref (#4495) github-actions Release checkpoint-sqlite (#4509) docstrings for checkpoint-sqlite Add delete_thread method to Checkpointer class (#4328) github-actions", "score": 0.57035583, "raw_content": null}, {"title": "Announcing LangGraph v0.1 & LangGraph Cloud: Running agents at scale ...", "url": "https://blog.langchain.dev/langgraph-cloud/", "content": "Announcing LangGraph v0.1 & LangGraph Cloud: Running agents at scale, reliably Our new infrastructure for running agents at scale, LangGraph Cloud, is available in beta. Separate from the langchain package, LangGraph’s core design philosophy is to help developers add better precision and control into agentic workflows, suitable for the complexity of real-world systems. LangGraph Cloud, currently in closed beta, is infrastructure for deploying your LangGraph agents in a scalable, fault tolerant way. LangGraph Cloud: Scalable agent deployment with integrated monitoring To complement the LangGraph framework, we also have a new runtime, LangGraph Cloud, now available in beta, which provides infrastructure purpose-built for deploying agents at scale. LangGraph Cloud also brings a more integrated experience for collaborating on, deploying, and monitoring your agentic app.", "score": 0.30856565, "raw_content": null}], "response_time": 0.46}', name='tavily_search', id='f4fbb8e8-f7d7-4ca5-969a-0f1d7941a069', tool_call_id='call_0_4f41d3f3-0512-440f-b690-56b476b58855'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_0_7a301df6-bb5a-41da-8af3-6e55f3999bed', 'function': {'arguments': '{"name":"LangGraph Release Date Review","birthday":"2023-01-01"}', 'name': 'human_assistance'}, 'type': 'function', 'index': 0}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 1940, 'total_tokens': 1973, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 1344}, 'prompt_cache_hit_tokens': 1344, 'prompt_cache_miss_tokens': 596}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_8802369eaa_prod0425fp8', 'id': 'fe865043-9bb9-4a2a-a725-033bf140d6d1', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--004e940b-d255-4a14-8f12-fc1e49f5bb93-0', tool_calls=[{'name': 'human_assistance', 'args': {'name': 'LangGraph Release Date Review', 'birthday': '2023-01-01'}, 'id': 'call_0_7a301df6-bb5a-41da-8af3-6e55f3999bed', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1940, 'output_tokens': 33, 'total_tokens': 1973, 'input_token_details': {'cache_read': 1344}, 'output_token_details': {}}), ToolMessage(content="Made a correction: {'name': 'LangGraph', 'birthday': 'Jan 17, 2024'}", name='human_assistance', id='c02a55a8-b41c-4ba9-b438-612dfafb370e', tool_call_id='call_0_7a301df6-bb5a-41da-8af3-6e55f3999bed'), AIMessage(content="It appears that LangGraph was released on **January 17, 2024**. Let me know if you'd like any additional details!", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 2005, 'total_tokens': 2033, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 1920}, 'prompt_cache_hit_tokens': 1920, 'prompt_cache_miss_tokens': 85}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_8802369eaa_prod0425fp8', 'id': '20e374eb-f0ef-478a-add2-6eb137e22d0e', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--218fa197-b63a-4830-a015-0edbf4c846cd-0', usage_metadata={'input_tokens': 2005, 'output_tokens': 28, 'total_tokens': 2033, 'input_token_details': {'cache_read': 1920}, 'output_token_details': {}})]), ('name', 'LangGraph'), ('birthday', 'Jan 17, 2024')])
    




    {'name': 'LangGraph', 'birthday': 'Jan 17, 2024'}


