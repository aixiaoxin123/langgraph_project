ÂèÇËÄÉÊñáÊ°£ÊïôÁ®ãÔºö
https://langchain-ai.github.io/langgraph/tutorials/get-started/6-time-travel/



```python
# https://python.langchain.com/docs/integrations/tools/tavily_search/

# Ëé∑ÂèñÂØÜÈí•ÁöÑÂú∞ÂùÄÔºö https://app.tavily.com/sign-in




import os
TAVILY_API_KEY="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"
os.environ["TAVILY_API_KEY"] = TAVILY_API_KEY

```


```python
from langchain_tavily import TavilySearch

tool = TavilySearch(max_results=5)
tools = [tool]
tool.invoke("What's a 'node' in LangGraph?")

```




    {'query': "What's a 'node' in LangGraph?",
     'follow_up_questions': None,
     'answer': None,
     'images': [],
     'results': [{'title': 'What is LangGraph? - IBM',
       'url': 'https://www.ibm.com/think/topics/langgraph',
       'content': 'LangGraph, created by LangChain, is an open source AI agent framework designed to build, deploy and manage complex generative AI agent workflows. At its core, LangGraph uses the power of graph-based architectures to model and manage the intricate relationships between various components of an AI agent workflow. LangGraph illuminates the processes within an AI workflow, allowing full transparency of the agent‚Äôs state. By combining these technologies with a set of APIs and tools, LangGraph provides users with a versatile platform for developing AI solutions and workflows including chatbots, state graphs and other agent-based systems. Nodes: In LangGraph, nodes represent individual components or agents within an AI workflow. LangGraph uses enhanced decision-making by modeling complex relationships between nodes, which means it uses AI agents to analyze their past actions and feedback.',
       'score': 0.90907925,
       'raw_content': None},
      {'title': 'Nodes and Edges | langchain-ai/langgraph-101 | DeepWiki',
       'url': 'https://deepwiki.com/langchain-ai/langgraph-101/2.2-nodes-and-edges',
       'content': 'Nodes and Edges | langchain-ai/langgraph-101 | DeepWiki Nodes and Edges Nodes and Edges What are Nodes and Edges? In LangGraph, a graph is composed of nodes connected by edges to form a directed workflow. Nodes are the workhorses of LangGraph - they are Python functions that receive the current graph state as input, perform operations, and return updates to that state. Edges define the flow of execution between nodes in a LangGraph. graph_builder.add_edge("retrieve_documents", "generate_response") Conditional edges use a function to determine the next node based on the current state. Building a Graph with Nodes and Edges graph_builder.add_node("retrieve_documents", retrieve_documents) graph_builder.add_edge("retrieve_documents", "generate_response") When designing nodes and edges in LangGraph: Nodes and Edges What are Nodes and Edges? Building a Graph with Nodes and Edges',
       'score': 0.8559598,
       'raw_content': None},
      {'title': "An Absolute Beginner's Guide to LangGraph.js",
       'url': 'https://techcommunity.microsoft.com/blog/educatordeveloperblog/an-absolute-beginners-guide-to-langgraph-js/4212496',
       'content': "We'll add the name and isHuman properties to our State object and update the sayHello and sayBye nodes to use these State object properties. Update the Graph's nodes and edges: We'll build a graph that returns a random fact or joke based on the user's input. Finally, inside src/index.ts, import and execute the Graph with a user input, inside the /joke-or-fact route: In this guide, we've covered the basics of LangGraph.js, building a simple graph that returns a random fact or joke based on user input. We've learned how to define nodes, edges, and state objects and how to add conditional routing to our Graph. LangGraph.js is a powerful tool for building complex workflows and managing State in your applications.",
       'score': 0.59457535,
       'raw_content': None},
      {'title': 'LangGraph cheatsheet ¬∑ GitHub',
       'url': 'https://gist.github.com/razhangwei/631a799e6bd69b26ce9c118c624cd80d',
       'content': 'This is an excellent LangGraph cheat sheet! LangGraph Cheat Sheet 3. Create Nodes Example Node Function: 4. Create the Graph 5. Add Nodes to the Graph 9. Compile the Graph Invoke the Graph StateGraph | Main class for creating a graph add_node() | Adds a node to the graph add_edge() | Adds a direct edge between two nodes add_conditional_edges() | Adds conditional edges based on a routing function set_entry_point() | Sets the starting node of the graph compile() | Compiles the graph into a RunnableGraph invoke() | Executes the graph with an initial state Send() | Dispatches tasks to multiple nodes in parallel This cheat sheet provides you with all essential steps, best practices, and examples for building LangGraph workflows efficiently! Footer Footer navigation',
       'score': 0.5654673,
       'raw_content': None},
      {'title': 'How to Build AI Agents with LangGraph: A Step-by-Step Guide',
       'url': 'https://medium.com/@lorevanoudenhove/how-to-build-ai-agents-with-langgraph-a-step-by-step-guide-5d84d9c7e832',
       'content': 'In this step, we‚Äôll define how the AI agent manages its state (the ongoing context of the conversation) and ensure it responds appropriately to the user‚Äôs input and tool output. This involves creating a template for the conversation, specifying the tools that the assistant will use, and configuring how the AI agent will respond to user input and trigger different functions (like calculating solar savings). This step ensures that the AI assistant can access and trigger the tools as needed during the conversation, creating a seamless interaction between the user and the assistant. By following these steps, you have successfully created an AI assistant using LangGraph that can calculate solar panel energy savings based on user inputs.',
       'score': 0.092532046,
       'raw_content': None}],
     'response_time': 1.71}




```python
import os
from langchain.chat_models import init_chat_model

API_KEY = "sk-123"

BASE_URL = "https://api.deepseek.com"

os.environ["OPENAI_API_KEY"] = API_KEY
os.environ["OPENAI_API_BASE"] = BASE_URL


llm = init_chat_model("openai:deepseek-chat")
```


```python
# ‰∏ªÁ®ãÂ∫è

from typing import Annotated

from langchain_tavily import TavilySearch
from langchain_core.messages import BaseMessage
from typing_extensions import TypedDict
from langchain_core.tools import tool
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode, tools_condition

from langgraph.types import Command, interrupt


from langchain_core.messages import ToolMessage
from langchain_core.tools import InjectedToolCallId, tool

from langgraph.types import Command, interrupt

class State(TypedDict):
    messages: Annotated[list, add_messages]



graph_builder = StateGraph(State)



tool = TavilySearch(max_results=2)

tools = [tool] # Ê∑ªÂä†human_assistanceÂ∑•ÂÖ∑

llm_with_tools = llm.bind_tools(tools)

def chatbot(state: State):
    return {"messages": [llm_with_tools.invoke(state["messages"])]}


graph_builder.add_node("chatbot", chatbot)

tool_node = ToolNode(tools=tools)
graph_builder.add_node("tools", tool_node)

graph_builder.add_conditional_edges(
    "chatbot",
    tools_condition,
)
# Any time a tool is called, we return to the chatbot to decide the next step
graph_builder.add_edge("tools", "chatbot")
graph_builder.add_edge(START, "chatbot")
graph = graph_builder.compile()
```


```python
# Ê∑ªÂä†ÂÜÖÂ≠òÂäüËÉΩ
from langgraph.checkpoint.memory import MemorySaver

memory = MemorySaver()
graph = graph_builder.compile(checkpointer=memory)
```


```python
from IPython.display import Image, display

try:
    display(Image(graph.get_graph().draw_mermaid_png()))
except Exception:
    # This requires some extra dependencies and is optional
    pass
```


    
![png](6%E6%97%B6%E9%97%B4%E6%97%85%E8%A1%8C_files/6%E6%97%B6%E9%97%B4%E6%97%85%E8%A1%8C_6_0.png)
    



```python
#‰∏éÊÇ®ÁöÑËÅäÂ§©Êú∫Âô®‰∫∫‰∫íÂä®


config = {"configurable": {"thread_id": "2"}}


user_input = (
    "I'm learning LangGraph. "
    "Could you do some research on it for me?"
)


# The config is the **second positional argument** to stream() or invoke()!
events = graph.stream(
    {"messages": [{"role": "user", "content": user_input}]},
    config,
    stream_mode="values",
)
for event in events:
    if "messages" in event:
        event["messages"][-1].pretty_print()
    
```

    ================================[1m Human Message [0m=================================
    
    I'm learning LangGraph. Could you do some research on it for me?
    ==================================[1m Ai Message [0m==================================
    Tool Calls:
      tavily_search (call_0_1124b302-9f52-4688-85e8-e016349dc888)
     Call ID: call_0_1124b302-9f52-4688-85e8-e016349dc888
      Args:
        query: LangGraph
        search_depth: advanced
    =================================[1m Tool Message [0m=================================
    Name: tavily_search
    
    {"query": "LangGraph", "follow_up_questions": null, "answer": null, "images": [], "results": [{"url": "https://www.ibm.com/think/topics/langgraph", "title": "What is LangGraph? - IBM", "content": "LangGraph, created by LangChain, is an open source AI agent framework designed to build, deploy and manage complex generative AI agent workflows. It provides a set of tools and libraries that enable users to create, run and optimize large language models (LLMs) in a scalable and efficient manner. At its core, LangGraph uses the power of graph-based architectures to model and manage the intricate relationships between various components of an AI agent workflow. [...] Agent systems: LangGraph provides a framework for building agent-based systems, which can be used in applications such as robotics, autonomous vehicles or video games.\n\nLLM applications: By using LangGraph‚Äôs capabilities, developers can build more sophisticated AI models that learn and improve over time. Norwegian Cruise Line uses LangGraph to compile, construct and refine guest-facing AI solutions. This capability allows for improved and personalized guest experiences. [...] By using a graph-based architecture, LangGraph enables users to scale artificial intelligence workflows without slowing down or sacrificing efficiency. LangGraph uses enhanced decision-making by modeling complex relationships between nodes, which means it uses AI agents to analyze their past actions and feedback. In the world of LLMs, this process is referred to as reflection.", "score": 0.9353998, "raw_content": null}, {"url": "https://github.com/langchain-ai/langgraph", "title": "langchain-ai/langgraph: Build resilient language agents as graphs.", "content": "LangGraph ‚Äî used by Replit, Uber, LinkedIn, GitLab and more ‚Äî is a low-level orchestration framework for building controllable agents. While langchain provides integrations and composable components to streamline LLM application development, the LangGraph library enables agent orchestration ‚Äî offering customizable architectures, long-term memory, and human-in-the-loop to reliably handle complex tasks.\n\n```\npip install -U langgraph\n```", "score": 0.8884594, "raw_content": null}], "response_time": 0.16}
    ==================================[1m Ai Message [0m==================================
    
    Here's what I found about LangGraph:
    
    1. **IBM's Overview**:
       - LangGraph is an open-source AI agent framework developed by LangChain. It is designed to build, deploy, and manage complex generative AI agent workflows.
       - It uses graph-based architectures to model relationships between components in AI workflows, making it scalable and efficient.
       - Applications include agent-based systems (e.g., robotics, autonomous vehicles) and large language model (LLM) applications. For example, Norwegian Cruise Line uses LangGraph to enhance guest-facing AI solutions.
       - LangGraph supports reflection, allowing AI agents to analyze past actions and feedback for improved decision-making.
    
       Read more: [IBM on LangGraph](https://www.ibm.com/think/topics/langgraph)
    
    2. **GitHub Repository**:
       - LangGraph is a low-level orchestration framework for building controllable agents. It is used by companies like Replit, Uber, LinkedIn, and GitLab.
       - It provides customizable architectures, long-term memory, and human-in-the-loop features to handle complex tasks reliably.
       - You can install it via pip:
         ```bash
         pip install -U langgraph
         ```
    
       Explore the GitHub repo: [langchain-ai/langgraph](https://github.com/langchain-ai/langgraph)
    
    Let me know if you'd like more details or specific aspects of LangGraph!
    


```python
snapshot = graph.get_state(config)
snapshot.next
```




    ()




```python
# replay

to_replay = None
for state in graph.get_state_history(config):
    print("Num Messages: ", len(state.values["messages"]), "Next: ", state.next)
    print("-" * 80)
    if len(state.values["messages"]) == 2: #ÊåáÂÆöË¶ÅÂõûÊîæÁöÑÁä∂ÊÄÅÁöÑÂ∫èÂè∑
        # We are somewhat arbitrarily selecting a specific state based on the number of chat messages in the state.
        to_replay = state
```

    Num Messages:  4 Next:  ()
    --------------------------------------------------------------------------------
    Num Messages:  3 Next:  ('chatbot',)
    --------------------------------------------------------------------------------
    Num Messages:  2 Next:  ('tools',)
    --------------------------------------------------------------------------------
    Num Messages:  1 Next:  ('chatbot',)
    --------------------------------------------------------------------------------
    Num Messages:  0 Next:  ('__start__',)
    --------------------------------------------------------------------------------
    


```python
#‰ªéÊ£ÄÊü•ÁÇπÊÅ¢Â§ç

print(to_replay.next)
print(to_replay.config)

```

    ('tools',)
    {'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f036bc4-23b2-6de4-8001-0145d4bbc81e'}}
    


```python
# ‰ªéÊüê‰∏™Êó∂ÂàªÂä†ËΩΩÁä∂ÊÄÅ

# The `checkpoint_id` in the `to_replay.config` corresponds to a state we've persisted to our checkpointer.
for event in graph.stream(None, to_replay.config, stream_mode="values"):
    if "messages" in event:
        event["messages"][-1].pretty_print()
        
```

    dict_items([('messages', [HumanMessage(content='Can you look up when LangGraph was released? When you have the answer, use the human_assistance tool for review.', additional_kwargs={}, response_metadata={}, id='6a9ae8cf-7eb3-4842-a4a4-2d2f8159f5db'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_0_fdff2329-f42d-42c8-ba5f-f1bd1ab74c19', 'function': {'arguments': '{"query":"LangGraph release date"}', 'name': 'tavily_search'}, 'type': 'function', 'index': 0}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 1362, 'total_tokens': 1385, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 1344}, 'prompt_cache_hit_tokens': 1344, 'prompt_cache_miss_tokens': 18}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_8802369eaa_prod0425fp8', 'id': '11756e3e-6840-43b0-ad5d-8b9a84c2a344', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--c0711883-34f8-48ce-a88a-504868074a25-0', tool_calls=[{'name': 'tavily_search', 'args': {'query': 'LangGraph release date'}, 'id': 'call_0_fdff2329-f42d-42c8-ba5f-f1bd1ab74c19', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1362, 'output_tokens': 23, 'total_tokens': 1385, 'input_token_details': {'cache_read': 1344}, 'output_token_details': {}}), ToolMessage(content='{"query": "LangGraph release date", "follow_up_questions": null, "answer": null, "images": [], "results": [{"title": "Releases ¬∑ langchain-ai/langgraph - GitHub", "url": "https://github.com/langchain-ai/langgraph/releases", "content": "Releases ¬∑ langchain-ai/langgraph GitHub Copilot Write better code with AI GitHub Advanced Security Find and fix vulnerabilities Code Search Find more, search less *   Why GitHub *   GitHub Advanced Security Enterprise-grade security features Search code, repositories, users, issues, pull requests... Releases: langchain-ai/langgraph Releases ¬∑ langchain-ai/langgraph github-actions github-actions [docs] LangGraph / LangGraph Platform docs updates (#4479) Add clear cache methods github-actions Changes since checkpoint==2.0.25 checkpoint: release 2.0.26 (#4708) docs(reference): filter class methods and add missing docstrings (#4463) github-actions Update python SDK docstrings (#4602) github-actions github-actions feat: CLI: Add main.py (#4637) github-actions github-actions fix for langgraph docstring fixes for libs/langgraph docs: update add_messages API ref (#4495) github-actions Release checkpoint-sqlite (#4509) docstrings for checkpoint-sqlite Add delete_thread method to Checkpointer class (#4328) github-actions", "score": 0.57035583, "raw_content": null}, {"title": "Announcing LangGraph v0.1 & LangGraph Cloud: Running agents at scale ...", "url": "https://blog.langchain.dev/langgraph-cloud/", "content": "Announcing LangGraph v0.1 & LangGraph Cloud: Running agents at scale, reliably Our new infrastructure for running agents at scale, LangGraph Cloud, is available in beta. Separate from the langchain package, LangGraph‚Äôs core design philosophy is to help developers add better precision and control into agentic workflows, suitable for the complexity of real-world systems. LangGraph Cloud, currently in closed beta, is infrastructure for deploying your LangGraph agents in a scalable, fault tolerant way. LangGraph Cloud: Scalable agent deployment with integrated monitoring To complement the LangGraph framework, we also have a new runtime, LangGraph Cloud, now available in beta, which provides infrastructure purpose-built for deploying agents at scale. LangGraph Cloud also brings a more integrated experience for collaborating on, deploying, and monitoring your agentic app.", "score": 0.30856565, "raw_content": null}], "response_time": 0.14}', name='tavily_search', id='ec43923b-3f7f-4af8-b429-e8f495fe614a', tool_call_id='call_0_fdff2329-f42d-42c8-ba5f-f1bd1ab74c19'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_0_cd7fb545-4808-420d-9599-9b5bd04ea93c', 'function': {'arguments': '{"name":"LangGraph Release Date","birthday":"2023-01-01"}', 'name': 'human_assistance'}, 'type': 'function', 'index': 0}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 1940, 'total_tokens': 1972, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 1920}, 'prompt_cache_hit_tokens': 1920, 'prompt_cache_miss_tokens': 20}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_8802369eaa_prod0425fp8', 'id': '3408c680-e1af-49f9-86ab-3e88ea9a726a', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--cf4bd759-f570-48e2-81d6-5d5352a4f2d0-0', tool_calls=[{'name': 'human_assistance', 'args': {'name': 'LangGraph Release Date', 'birthday': '2023-01-01'}, 'id': 'call_0_cd7fb545-4808-420d-9599-9b5bd04ea93c', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1940, 'output_tokens': 32, 'total_tokens': 1972, 'input_token_details': {'cache_read': 1920}, 'output_token_details': {}}), ToolMessage(content="Made a correction: {'name': 'LangGraph', 'birthday': 'Jan 17, 2024'}", name='human_assistance', id='4d24e375-fdb4-4e6a-9724-255ce0189309', tool_call_id='call_0_cd7fb545-4808-420d-9599-9b5bd04ea93c'), AIMessage(content="LangGraph was released on January 17, 2024. The information has been reviewed and confirmed. Let me know if you'd like further details!", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 2004, 'total_tokens': 2035, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 1920}, 'prompt_cache_hit_tokens': 1920, 'prompt_cache_miss_tokens': 84}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_8802369eaa_prod0425fp8', 'id': '6d6488c8-0bc1-45a8-a1b5-29087490b223', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--bb451740-bb5e-4d17-af36-9dbe62a820e5-0', usage_metadata={'input_tokens': 2004, 'output_tokens': 31, 'total_tokens': 2035, 'input_token_details': {'cache_read': 1920}, 'output_token_details': {}})]), ('name', 'LangGraph'), ('birthday', 'Jan 17, 2024')])
    




    {'name': 'LangGraph', 'birthday': 'Jan 17, 2024'}


